{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a209f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdc7e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: \"\\L\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\L\"? A raw string is also an option.\n",
      "<>:2: SyntaxWarning: \"\\L\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\L\"? A raw string is also an option.\n",
      "C:\\Users\\Weverson Barbieri\\AppData\\Local\\Temp\\ipykernel_10768\\1924807895.py:2: SyntaxWarning: \"\\L\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\L\"? A raw string is also an option.\n",
      "  df_gm = pd.read_csv(\"C:\\Language_Projects\\Language_Projects\\Python\\Flagship_1\\part-number-datasets-cleaning\\data\\\\raw_datasets\\gmR.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Read the .csv file\n",
    "df_gm = pd.read_csv(\"C:\\Language_Projects\\Language_Projects\\Python\\Flagship_1\\part-number-datasets-cleaning\\data\\\\raw_datasets\\gmR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bf4565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ModType       2886 non-null   object\n",
      " 1   Hardware      2881 non-null   object\n",
      " 2   GM CAL №      2834 non-null   object\n",
      " 3   ID            2448 non-null   object\n",
      " 4   P/N           2873 non-null   object\n",
      " 5   Bosch 0261 №  1947 non-null   object\n",
      " 6   VIN Example   3458 non-null   object\n",
      " 7   EPC PN        3180 non-null   object\n",
      " 8   Year          3540 non-null   object\n",
      " 9   Make & Model  3558 non-null   object\n",
      " 10  Engine        3317 non-null   object\n",
      " 11  Prog Info     835 non-null    object\n",
      "dtypes: object(12)\n",
      "memory usage: 403.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the df info\n",
    "df_gm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bac312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where all cols have null (NaN) values,\n",
    "# keeping only rows with at least one valid (non-null) entry.\n",
    "df_gm_not_allNull = df_gm[~df_gm.isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514b4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where more than one col has a non-null value.\n",
    "# This removes rows with only a single non-null entry, ensuring each row has multiple valid data points.\n",
    "df_gm_more_than_one_not_null = df_gm_not_allNull[df_gm_not_allNull.notnull().sum(axis=1) != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea07db8",
   "metadata": {},
   "source": [
    "### GM Manufacturer and Module Type DataFrames\n",
    "\n",
    "General Motors (GM) includes several vehicle brands, and the information related to engine modules may differ between these brands. Therefore, separate DataFrames will be created for each module type. Each DataFrame will be named according to the value in the first column, which represents the module type (`ModType`). This approach ensures that data for each module type is organized and easily accessible for analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6f936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_rows(df):\n",
    "    '''\n",
    "    Iterate over all columns and fill out all null values.\n",
    "\n",
    "    Parameters: \n",
    "        df (DataFrame): main df.\n",
    "\n",
    "    Returns:\n",
    "        df: Return a df with the null values filled out\n",
    "    '''\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].fillna(\"Not Available\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540a3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the whitespaces\n",
    "def remove_whitespaces(df):\n",
    "    # Loop to iterate over all cols\n",
    "    for col in df.columns:\n",
    "        # Remove the writespaces\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8140749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split multiple part numbers originally in the same line to one row each\n",
    "def split_part_numbers(df, col):\n",
    "\n",
    "    # Call the function to remove the whitespaces\n",
    "    df_rm_spaces = remove_whitespaces(df)\n",
    "\n",
    "    df_copy = df_rm_spaces.copy()\n",
    "\n",
    "    # Create a list with the items in each row \n",
    "    df_copy[col] = df_copy[col].str.split(\",\")\n",
    "    # Explode the items in different rows each and keep the info from the other rows\n",
    "    df_splitted = df_copy.explode(col)\n",
    "    # Return the df with the exploded part numbers\n",
    "    return df_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c449b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Weverson Barbieri\\AppData\\Local\\Temp\\ipykernel_10768\\1009899977.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_gm_more_than_one_not_null['Hardware'] = df_gm_more_than_one_not_null['Hardware'].fillna(method='ffill')\n",
      "C:\\Users\\Weverson Barbieri\\AppData\\Local\\Temp\\ipykernel_10768\\1009899977.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gm_more_than_one_not_null['Hardware'] = df_gm_more_than_one_not_null['Hardware'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Fill null values in the 'Hardware' col by propagating the last valid value forward.\n",
    "# method='ffill' -> copies the value from the previous row into rows with null values.\n",
    "df_gm_more_than_one_not_null['Hardware'] = df_gm_more_than_one_not_null['Hardware'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527cdce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all lines with the repeated cols\n",
    "repeated_cols_index_list = df_gm_more_than_one_not_null[df_gm_more_than_one_not_null['ModType'] == 'ModType'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d847938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all lines with repeated cols\n",
    "df_gm_rm_repeated_cols = df_gm_more_than_one_not_null.drop(index=repeated_cols_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de24fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all cols to be deleted\n",
    "col_map = ['ModType', 'ID', 'VIN Example', 'Year', 'Make & Model', 'Engine', 'Prog Info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a9b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove no needed cols according to the map\n",
    "df_gm_rm_cols = df_gm_rm_repeated_cols.drop(columns=col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f74f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hardware', 'GM CAL №', 'P/N', 'Bosch 0261 №', 'EPC PN'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the cols\n",
    "df_gm_rm_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1fae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map cols will be renamed\n",
    "rename_mapping_cols = {\n",
    "    \"P/N\": \"Service №\",\n",
    "    \"Bosch 0261 №\": \"Other PN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d959db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols from P/N and Bosch 0261 №\n",
    "df_gm_rn_cols = df_gm_rm_cols.rename(columns=rename_mapping_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "857ac338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to fill out null values\n",
    "df_gm_fill_null_values = fill_null_rows(df_gm_rn_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62ec67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hardware', 'GM CAL №', 'Service №', 'Other PN', 'EPC PN'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the cols\n",
    "df_gm_fill_null_values.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24a870",
   "metadata": {},
   "source": [
    "### Call the function to the explode all items of the cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f9d80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_explo_hdw_col = split_part_numbers(df_gm_fill_null_values, \"Hardware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e4a3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_explo_gmCal_col = split_part_numbers(df_gm_explo_hdw_col, \"GM CAL №\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2655fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_explo_servN_col = split_part_numbers(df_gm_explo_gmCal_col, \"Service №\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c494d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_explo_otherPn_col = split_part_numbers(df_gm_explo_servN_col, \"Other PN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37630386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_explo_epnPn_col = split_part_numbers(df_gm_explo_otherPn_col, \"EPC PN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce93b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df_gm_reset_index = df_gm_explo_epnPn_col.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64ebdd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4160 entries, 0 to 4159\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Hardware   4160 non-null   object\n",
      " 1   GM CAL №   4160 non-null   object\n",
      " 2   Service №  4160 non-null   object\n",
      " 3   Other PN   4160 non-null   object\n",
      " 4   EPC PN     4160 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 162.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the df info\n",
    "df_gm_reset_index.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f023d04",
   "metadata": {},
   "source": [
    "## Standardizing Part Number Dataset Columns\n",
    "Each part number dataset contains columns with different names because they originate from different manufacturers. One of the goals of cleaning these datasets is to create a standard format that allows for the identification of the hardware part number when inputting other part numbers, such as software part numbers or system part numbers.\n",
    "\n",
    "Since the identification of the hardware part number will be performed by inputting multiple part numbers at once (via a .csv file), it is necessary — except for the hardware column — to rename the other columns to a standard format: `pnNum` (e.g., `pn1`, `pn2`, etc.). This ensures consistency and enables automated matching and processing across datasets from various manufacturers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "130d3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col_names(df):\n",
    "    '''\n",
    "    Except the column hardware, the function standardize the names for pnNumber (pn1, pn2).\n",
    "    Needed due to each part number dataset has different column names, so that \n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): main df.\n",
    "    col_list (list): List of original column names.\n",
    "\n",
    "    Returns\n",
    "    df: Return the main df with the renamed cols\n",
    "\n",
    "    '''\n",
    "\n",
    "    # List with the col names\n",
    "    col_name_list = list(df.columns) \n",
    "    \n",
    "    # Dict to append the old names (key): new names (values) \n",
    "    new_cols_dict = {}\n",
    "\n",
    "    # Count the items under the col list\n",
    "    col_num = len(col_name_list)\n",
    "    # Loop to iterate over the list\n",
    "    for col in col_name_list:\n",
    "        # Condition to define when lower the col name and when rename it\n",
    "        if col == \"Hardware\":\n",
    "            new_cols_dict[col] = col.lower()\n",
    "        else:\n",
    "            # Convert the string to number to sum with the stirng pn and\n",
    "            # append as value to the dict\n",
    "            new_cols_dict[col] = \"pn\" + str(col_num)\n",
    "            # Return the number from string to int\n",
    "            col_num = int(col_num)\n",
    "        \n",
    "        # Subtract one to create the next col name\n",
    "        num_col = col_num - 1\n",
    "        col_num = num_col\n",
    "\n",
    "    # Return the main df with the cols remanes\n",
    "    return df.rename(columns=new_cols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ade8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to rename the cols\n",
    "df_gm_rn_cols = rename_col_names(df_gm_reset_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to .csv file\n",
    "df_gm_rn_cols.to_csv(\"C:\\Language_Projects\\Language_Projects\\Python\\Flagship_1\\part-number-datasets-cleaning\\data\\data_cleaned\\pn-gm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a211340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_datasets_to_db(df, df_name=str):\n",
    "    \n",
    "    '''\n",
    "    Import the df cleaned to the db on postgreSQL\n",
    "\n",
    "    Parameters: \n",
    "        df (DataFrame): main df to import to the postgreSQL db.\n",
    "        df_name: string to label the df into the db.\n",
    "\n",
    "    Returns: \n",
    "        Import the df to the db.\n",
    "    '''\n",
    "    # Setting up the connection with the PostgreSQL\n",
    "    dbname=\"prescreen_diag_data_api\"\n",
    "    user=\"postgres\"\n",
    "    password=\"shakey-10\"\n",
    "    host=\"localhost\"\n",
    "    port=\"5432\"\n",
    "\n",
    "    # String connection for SQLAlchemy (using psycopg2 as driver)\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}\")\n",
    "\n",
    "    return df.to_sql(df_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94f50ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function to import the df cleaned to the postgreSQLdb\n",
    "import_datasets_to_db(df_gm_rn_cols, 'part_numbers_gm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
